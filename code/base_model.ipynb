{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This file contains functions that can be easily used for other parts of the experiment.\n",
    " To make new data mods, duplicate this file and add a new function to replace \"basic_preprocessing\" in this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.create_dataframe import read_data\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Turtle_Tortoise        500\n",
       "Crocodile_Alligator    500\n",
       "Snake                  500\n",
       "Frog                   499\n",
       "Iguana                 489\n",
       "Salamander             468\n",
       "Gecko                  316\n",
       "Chameleon              263\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe using other file's code\n",
    "\n",
    "reptiles=read_data([\"Lizard\",\"Toad\"])\n",
    "reptiles.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_preprocess(dataframe):\n",
    "    # Basic preprocessing \n",
    "\n",
    "    # prepare X\n",
    "    img_list = list(dataframe['image'])\n",
    "    data_img = []\n",
    "    for each in img_list:\n",
    "                each_img = cv2.cvtColor(each, cv2.COLOR_BGR2RGB)\n",
    "                #Resize the images:\n",
    "                each_img_resized = cv2.resize(each_img, (128,128))\n",
    "                #Save arrays to a list:\n",
    "                data_img.append(each_img_resized)\n",
    "    # Converting list to numpy array\n",
    "    X = np.array(data_img)\n",
    "\n",
    "    # prepare y\n",
    "    y = OneHotEncoder(dtype='int8', sparse=False).fit_transform(dataframe['target'].values.reshape(-1,1))\n",
    "\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (2403, 128, 128, 3)\n",
      "y_train shape:  (2403, 8)\n",
      "X_val shape  :  (601, 128, 128, 3)\n",
      "y_val shape  :  (601, 8)\n",
      "X_test shape :  (531, 128, 128, 3)\n",
      "y_test shape :  (531, 8)\n"
     ]
    }
   ],
   "source": [
    "X,y= basic_preprocess(reptiles) ## replace this to change preprocessing\n",
    "\n",
    "X_data, X_test, y_data, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_val shape  : ', X_val.shape)\n",
    "print('y_val shape  : ', y_val.shape)\n",
    "print('X_test shape : ', X_test.shape)\n",
    "print('y_test shape : ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X_train,y_train,X_val):\n",
    "    #  code adapted from:\n",
    "    #  https://pub.towardsai.net/multiclass-image-classification-hands-on-with-keras-and-tensoflow-e1cf434f3467\n",
    "\n",
    "\n",
    "    train_gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                               rotation_range = 45,\n",
    "                               zoom_range=0.2,\n",
    "                               height_shift_range = 0.5,\n",
    "                               width_shift_range = 0.5)\n",
    "    validation_gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                    rotation_range = 45,\n",
    "                                    zoom_range=0.2,\n",
    "                                    height_shift_range = 0.5,\n",
    "                                    width_shift_range = 0.5)\n",
    "    train_gen.fit(X_train)\n",
    "    validation_gen.fit(X_val)\n",
    "    batch_size = 64\n",
    "    epochs = 10\n",
    "    base = Xception(include_top=False, \n",
    "                weights='imagenet', \n",
    "                input_shape=(128,128,3))\n",
    "    x = base.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    head = Dense(y_train.shape[1], activation='softmax')(x)\n",
    "    model = Model(inputs=base.input, outputs=head)\n",
    "    model.compile(optimizer=Adam(lr=0.0001),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=['accuracy'], run_eagerly=True)\n",
    "    \n",
    "    fit = model.fit_generator(\n",
    "               train_gen.flow(X_train, y_train,\n",
    "               batch_size=batch_size),\n",
    "               epochs = epochs,\n",
    "               validation_data = validation_gen.flow(X_val, y_val)\n",
    ")\n",
    "\n",
    "    return model,fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikafox/opt/miniconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/var/folders/5b/sjkc4b8n0hs41zd03hxr66100000gn/T/ipykernel_30749/1192349572.py:27: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  fit = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "38/38 [==============================] - 206s 5s/step - loss: 1.9481 - accuracy: 0.2588 - val_loss: 1.8977 - val_accuracy: 0.2912\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 205s 5s/step - loss: 1.4599 - accuracy: 0.5198 - val_loss: 1.4693 - val_accuracy: 0.4908\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 205s 5s/step - loss: 1.1353 - accuracy: 0.6205 - val_loss: 1.4119 - val_accuracy: 0.5674\n",
      "Epoch 4/10\n",
      " 4/38 [==>...........................] - ETA: 2:53 - loss: 0.9989 - accuracy: 0.6758"
     ]
    }
   ],
   "source": [
    "model,fit=fit_model(X_train,y_train,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(model_fit):\n",
    "    history_df = pd.DataFrame(model_fit.history)\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history_df['loss'], label='training loss')\n",
    "    plt.plot(history_df['val_loss'], label='validation loss')\n",
    "    plt.title('Model Loss Function')\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history_df['accuracy'], label='training accuracy')\n",
    "    plt.plot(history_df['val_accuracy'], label='validation accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.legend();\n",
    "\n",
    "\n",
    "def make_conf_matrix(model):\n",
    "    #  Predicting labels from X_test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Converting prediction classes from one hot encoding to list\n",
    "    # Argmax returns the position of the largest value\n",
    "    y_pred_classes = np.argmax(y_pred, axis = 1)\n",
    "    # Convert test labels from one hot encoding to list\n",
    "    y_test_classes = np.argmax(y_test, axis = 1)\n",
    "    # Create the confusion matrix\n",
    "    confmx = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    f, ax = plt.subplots(figsize = (8,8))\n",
    "    sns.heatmap(confmx, annot=True, fmt='.1f', ax = ax)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key for Confusion Matrix\n",
    "\n",
    "### 0 - Crocodile\n",
    "### 1 - Frog\n",
    "### 2 - Gecko\n",
    "### 3 - Iguana\n",
    "### 4 - Salamander\n",
    "### 5 - Snake\n",
    "### 6 - Turtle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots(fit)\n",
    "make_conf_matrix(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
