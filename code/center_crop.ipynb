{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from random import choice,sample\n",
    "from ipynb.fs.full.create_dataframe import read_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(im, crop_pixels = 10):\n",
    "    return im[crop_pixels:im.shape[0] - crop_pixels, crop_pixels:im.shape[1] - crop_pixels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_preprocess(dataframe):\n",
    "    # Basic preprocessing \n",
    "    dataframe=dataframe[dataframe.astype(str)['image'] != '[]']\n",
    "    # prepare X\n",
    "    img_list = list(dataframe['image'])\n",
    "    data_img = []\n",
    "    for each in img_list:\n",
    "                each_img = cv2.cvtColor(each, cv2.COLOR_BGR2RGB)\n",
    "                #Resize the images:\n",
    "                each_img_resized = cv2.resize(each_img, (128,128))\n",
    "\n",
    "                each_img_cropped=center_crop(each_img_resized)\n",
    "\n",
    "        \n",
    "                #Save arrays to a list:\n",
    "                data_img.append(each_img_cropped)\n",
    "    # Converting list to numpy array\n",
    "    X = np.array(data_img)\n",
    "\n",
    "    # prepare y\n",
    "    y = OneHotEncoder(dtype='int8', sparse=False).fit_transform(dataframe['target'].values.reshape(-1,1))\n",
    "\n",
    "    return X,y\n",
    "\n",
    "def fit_model(X_train,y_train,X_val,y_val):\n",
    "    #  code adapted from:\n",
    "    #  https://pub.towardsai.net/multiclass-image-classification-hands-on-with-keras-and-tensoflow-e1cf434f3467\n",
    "\n",
    "\n",
    "    train_gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                               rotation_range = 45,\n",
    "                               zoom_range=0.2,\n",
    "                               height_shift_range = 0.5,\n",
    "                               width_shift_range = 0.5)\n",
    "    validation_gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                    rotation_range = 45,\n",
    "                                    zoom_range=0.2,\n",
    "                                    height_shift_range = 0.5,\n",
    "                                    width_shift_range = 0.5)\n",
    "    train_gen.fit(X_train)\n",
    "    validation_gen.fit(X_val)\n",
    "    batch_size = 64\n",
    "    epochs = 10\n",
    "    base = Xception(include_top=False, \n",
    "                weights='imagenet', \n",
    "                input_shape=X_train[1].shape)\n",
    "    x = base.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    head = Dense(y_train.shape[1], activation='softmax')(x)\n",
    "    model = Model(inputs=base.input, outputs=head)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=['accuracy'], run_eagerly=True)\n",
    "    \n",
    "    fit = model.fit_generator(\n",
    "               train_gen.flow(X_train, y_train,\n",
    "               batch_size=batch_size),\n",
    "               epochs = epochs,\n",
    "               validation_data = validation_gen.flow(X_val, y_val)\n",
    ")\n",
    "\n",
    "    return model,fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Frog_Toad          500\n",
       "Turtle_Tortoise    500\n",
       "Lizard             500\n",
       "Snake              499\n",
       "Salamander         466\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe using other file's code\n",
    "reptiles=read_data([\"Crocodile_Alligator\",\"Gecko\"])\n",
    "reptiles.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reptiles['image']=reptiles['image'].apply(lambda x: center_crop(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 300, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reptiles['image'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (1676, 108, 108, 3)\n",
      "y_train shape:  (1676, 5)\n",
      "X_val shape  :  (419, 108, 108, 3)\n",
      "y_val shape  :  (419, 5)\n",
      "X_test shape :  (370, 108, 108, 3)\n",
      "y_test shape :  (370, 5)\n"
     ]
    }
   ],
   "source": [
    "X,y= basic_preprocess(reptiles) ## replace this to change preprocessing\n",
    "\n",
    "X_data, X_test, y_data, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_val shape  : ', X_val.shape)\n",
    "print('y_val shape  : ', y_val.shape)\n",
    "print('X_test shape : ', X_test.shape)\n",
    "print('y_test shape : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 108, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 15:31:53.958199: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/var/folders/5b/sjkc4b8n0hs41zd03hxr66100000gn/T/ipykernel_65113/661476147.py:55: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  fit = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 450s 17s/step - loss: 1.5012 - accuracy: 0.3437 - val_loss: 1.6108 - val_accuracy: 0.3437\n",
      "Epoch 2/10\n",
      " 8/27 [=======>......................] - ETA: 4:44 - loss: 1.2599 - accuracy: 0.5430"
     ]
    }
   ],
   "source": [
    "model,fit=fit_model(X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(model_fit):\n",
    "    history_df = pd.DataFrame(model_fit.history)\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history_df['loss'], '.', linestyle='solid', label='training loss')\n",
    "    plt.plot(history_df['val_loss'], '.', linestyle='solid', label='validation loss')\n",
    "    plt.title('Model Loss Function')\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history_df['accuracy'], '.', linestyle='solid', label='training accuracy')\n",
    "    plt.plot(history_df['val_accuracy'], '.', linestyle='solid', label='validation accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.legend();\n",
    "\n",
    "def getPredTestClasses(model, X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Converting prediction classes from one hot encoding to list\n",
    "    # Argmax returns the position of the largest value\n",
    "    y_pred_classes = np.argmax(y_pred, axis = 1)\n",
    "    # Convert test labels from one hot encoding to list\n",
    "    y_test_classes = np.argmax(y_test, axis = 1)\n",
    "    return y_test_classes,y_pred_classes\n",
    "\n",
    "def make_conf_matrix(y_test_classes,y_pred_classes):\n",
    "    # Create the confusion matrix\n",
    "    confmx = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    f, ax = plt.subplots(figsize = (8,8))\n",
    "    sns.heatmap(confmx, annot=True, fmt='.1f', ax = ax)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show();\n",
    "\n",
    "make_plots(fit)\n",
    "y_test_classes,y_pred_classes= getPredTestClasses(model, X_test)\n",
    "make_conf_matrix(y_test_classes,y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_key(y,data):\n",
    "    dic={}\n",
    "    for s in np.arange(0, len(reptiles), 520, dtype=int):\n",
    "        key=data[\"target\"][s]\n",
    "        key_value=np.where(y[s] == 1)[0][0]\n",
    "        dic[key]=key_value\n",
    "    return dic\n",
    "\n",
    "predicted=pd.DataFrame({\"True\":y_test_classes,\"Pred\":y_pred_classes})\n",
    "\n",
    "# change classes to actual labels\n",
    "label_key = create_label_key(y,reptiles)\n",
    "predicted=predicted.replace({\"True\": label_key,\"Pred\":label_key})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_misclassified(predicted):\n",
    "    misclassified=predicted.loc[~(predicted['True'] == predicted['Pred'])]\n",
    "    indices = sample(misclassified.index.to_list(),8)\n",
    "    i = 1\n",
    "    plt.figure(figsize=(14,7))\n",
    "    for each in indices:\n",
    "        plt.subplot(2,4,i)\n",
    "        plt.imshow(Image.fromarray(X_test[each]))\n",
    "        plt.title(\"True:\"+misclassified['True'].loc[each]+\"\\nPredicted: \"+misclassified['Pred'].loc[each])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        i += 1\n",
    "\n",
    "show_sample_misclassified(predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
