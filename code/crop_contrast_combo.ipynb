{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikafox/opt/miniconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from random import choice,sample\n",
    "from ipynb.fs.full.create_dataframe import read_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(im, crop_pixels = 10):\n",
    "    return im[crop_pixels:im.shape[0] - crop_pixels, crop_pixels:im.shape[1] - crop_pixels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_preprocess(dataframe):\n",
    "    # Basic preprocessing \n",
    "    dataframe=dataframe[dataframe.astype(str)['image'] != '[]']\n",
    "    # prepare X\n",
    "    img_list = list(dataframe['image'])\n",
    "    data_img = []\n",
    "    for each in img_list:\n",
    "                each_img = cv2.cvtColor(each, cv2.COLOR_BGR2RGB)\n",
    "                #Resize the images:\n",
    "                each_img_resized = cv2.resize(each_img, (128,128))\n",
    "\n",
    "                each_img_cropped=center_crop(each_img_resized)\n",
    "\n",
    "        \n",
    "                #Save arrays to a list:\n",
    "                data_img.append(each_img_cropped)\n",
    "    # Converting list to numpy array\n",
    "    X = np.array(data_img)\n",
    "\n",
    "    # prepare y\n",
    "    y = OneHotEncoder(dtype='int8', sparse=False).fit_transform(dataframe['target'].values.reshape(-1,1))\n",
    "\n",
    "    return X,y\n",
    "\n",
    "def fit_model(X_train,y_train,X_val,y_val):\n",
    "    #  code adapted from:\n",
    "    #  https://pub.towardsai.net/multiclass-image-classification-hands-on-with-keras-and-tensoflow-e1cf434f3467\n",
    "\n",
    "\n",
    "    train_gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                               rotation_range = 45,\n",
    "                               zoom_range=0.2,\n",
    "                               height_shift_range = 0.5,\n",
    "                               width_shift_range = 0.5)\n",
    "    validation_gen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                    rotation_range = 45,\n",
    "                                    zoom_range=0.2,\n",
    "                                    height_shift_range = 0.5,\n",
    "                                    width_shift_range = 0.5)\n",
    "    train_gen.fit(X_train)\n",
    "    validation_gen.fit(X_val)\n",
    "    batch_size = 64\n",
    "    epochs = 10\n",
    "    base = Xception(include_top=False, \n",
    "                weights='imagenet', \n",
    "                input_shape=X_train[1].shape)\n",
    "    x = base.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    head = Dense(y_train.shape[1], activation='softmax')(x)\n",
    "    model = Model(inputs=base.input, outputs=head)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=['accuracy'], run_eagerly=True)\n",
    "    \n",
    "    fit = model.fit_generator(\n",
    "               train_gen.flow(X_train, y_train,\n",
    "               batch_size=batch_size),\n",
    "               epochs = epochs,\n",
    "               validation_data = validation_gen.flow(X_val, y_val)\n",
    ")\n",
    "\n",
    "    return model,fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bright_contrast (image, alpha=1, beta=0):\n",
    "    return cv2.convertScaleAbs(image, alpha=alpha, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reptiles=read_data([\"Lizard\",\"Toad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reptiles[\"image\"]=reptiles[\"image\"].apply(lambda x: bright_contrast(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 300, 4)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reptiles['image'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (2460, 108, 108, 3)\n",
      "y_train shape:  (2460, 8)\n",
      "X_val shape  :  (616, 108, 108, 3)\n",
      "y_val shape  :  (616, 8)\n",
      "X_test shape :  (543, 108, 108, 3)\n",
      "y_test shape :  (543, 8)\n"
     ]
    }
   ],
   "source": [
    "X,y= basic_preprocess(reptiles) ## replace this to change preprocessing\n",
    "\n",
    "X_data, X_test, y_data, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_val shape  : ', X_val.shape)\n",
    "print('y_val shape  : ', y_val.shape)\n",
    "print('X_test shape : ', X_test.shape)\n",
    "print('y_test shape : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 108, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/sjkc4b8n0hs41zd03hxr66100000gn/T/ipykernel_47604/661476147.py:55: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  fit = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================] - 495s 13s/step - loss: 1.9340 - accuracy: 0.2687 - val_loss: 1.9694 - val_accuracy: 0.2955\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 467s 12s/step - loss: 1.4916 - accuracy: 0.5065 - val_loss: 1.6454 - val_accuracy: 0.4659\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 664s 17s/step - loss: 1.1563 - accuracy: 0.6098 - val_loss: 1.2800 - val_accuracy: 0.5877\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 580s 15s/step - loss: 0.9732 - accuracy: 0.6764 - val_loss: 1.0492 - val_accuracy: 0.6640\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 547s 14s/step - loss: 0.8245 - accuracy: 0.7175 - val_loss: 0.9415 - val_accuracy: 0.7029\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 521s 13s/step - loss: 0.7823 - accuracy: 0.7333 - val_loss: 0.9762 - val_accuracy: 0.6640\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 522s 13s/step - loss: 0.6645 - accuracy: 0.7809 - val_loss: 0.8722 - val_accuracy: 0.7110\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 1051s 27s/step - loss: 0.6303 - accuracy: 0.7846 - val_loss: 0.7971 - val_accuracy: 0.7305\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 9933s 261s/step - loss: 0.5964 - accuracy: 0.7976 - val_loss: 0.8337 - val_accuracy: 0.7256\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 8932s 235s/step - loss: 0.5509 - accuracy: 0.8146 - val_loss: 0.8233 - val_accuracy: 0.7321\n"
     ]
    }
   ],
   "source": [
    "model,fit=fit_model(X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
